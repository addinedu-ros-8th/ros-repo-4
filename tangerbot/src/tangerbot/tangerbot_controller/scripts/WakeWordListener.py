#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from tangerbot_msgs.msg import RawVoice  # RawVoice ë©”ì‹œì§€ ì„í¬íŠ¸
from pinky_interfaces.srv import Emotion

import speech_recognition as sr
import time
import sounddevice as sd
import numpy as np
import io
import wave

SAMPLE_RATE = 16000
FRAME_SIZE = 1024
SILENCE_THRESHOLD = 2  # 2ì´ˆ ì¹¨ë¬µ ì‹œ ì¢…ë£Œ

class WakeWordListener(Node):
    def __init__(self):
        super().__init__('wake_word_listener')

        self.wake_pub_ = self.create_publisher(String, '/wake_word', 10)
        self.raw_voice_pub_ = self.create_publisher(RawVoice, '/raw_voice', 10)  # âœ… í¼ë¸”ë¦¬ì…” ì¶”ê°€

        # ê°ì • ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸
        self.emotion_cli = self.create_client(Emotion, 'set_emotion')
        while not self.emotion_cli.wait_for_service(timeout_sec=1.0):
<<<<<<< HEAD
            self.get_logger().info('ê°ì • ì„œë¹„ìŠ¤ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...')
=======
            self.get_logger().info('â³ ê°ì • ì„œë¹„ìŠ¤ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...')
            
        self.voice_cli = self.create_client(HandleRawVoice, 'handle_raw_voice')
        # while not self.voice_cli.wait_for_service(timeout_sec=1.0):
        #     self.get_logger().info('ğŸ™ ìŒì„± ì²˜ë¦¬ ì„œë¹„ìŠ¤ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...')
>>>>>>> dev

        self.recognizer = sr.Recognizer()
        self.mic = sr.Microphone(device_index=1)
        self.trigger_word = "í•‘í‚¤ì•¼"
        self.listening = False

        self.get_logger().info("Wake word listener ì‹œì‘ë¨. 'í•‘í‚¤ì•¼'ë¼ê³  ë§í•˜ì„¸ìš”.")
        self.timer = self.create_timer(0.1, self.listen_loop)

    def listen_loop(self):
        if self.listening:
            return

        with self.mic as source:
            self.get_logger().info("ëŒ€ê¸° ì¤‘...")
            self.recognizer.adjust_for_ambient_noise(source)
            audio = self.recognizer.listen(source)

        try:
            text = self.recognizer.recognize_google(audio, language="ko-KR")
            self.get_logger().info(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")

            if self.trigger_word == text:
                self.listening = True

                # wake word í¼ë¸”ë¦¬ì‹œ
                wake_msg = String()
                wake_msg.data = self.trigger_word
                self.wake_pub_.publish(wake_msg)

                # ê°ì • ìƒíƒœ 'basic' ìš”ì²­
                req = Emotion.Request()
                req.emotion = "basic"
                self.emotion_cli.call_async(req)

                # ìŒì„± ë…¹ìŒ
                audio_np = self.record_until_silence()
                if audio_np is not None:
                    self.publish_raw_voice(audio_np)
                else:
                    self.get_logger().warn("âŒ ìœ íš¨í•œ ìŒì„± ì—†ìŒ")
                    req = Emotion.Request()
                    req.emotion = "sad"
                    self.emotion_cli.call_async(req)

                self.listening = False

        except sr.UnknownValueError:
            self.get_logger().warn("ğŸ¤· ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            req = Emotion.Request()
            req.emotion = "sad"
            self.emotion_cli.call_async(req)

        except sr.RequestError as e:
            self.get_logger().error(f"âŒ STT ì˜¤ë¥˜: {e}")
            req = Emotion.Request()
            req.emotion = "sad"
            self.emotion_cli.call_async(req)

    def record_until_silence(self):
        self.get_logger().info("ğŸ¤ ë§í•˜ì„¸ìš”! (2ì´ˆ ì¹¨ë¬µ ì‹œ ì¢…ë£Œ)")
        buffer = []
        silence_start = None
        speech_detected = False
        start_time = time.time()
        stop_recording = False

        def callback(indata, frames, time_info, status):
            nonlocal buffer, silence_start, speech_detected, start_time, stop_recording
            int_data = (indata[:, 0] * 32767).astype(np.int16)
            frame_bytes = int_data.tobytes()

            if self.is_speech(frame_bytes):
                buffer.append(int_data.copy())
                speech_detected = True
                silence_start = None
            else:
                if speech_detected:
                    buffer.append(int_data.copy())
                if silence_start is None:
                    silence_start = time.time()
                elif time.time() - silence_start > SILENCE_THRESHOLD:
                    stop_recording = True

            if not speech_detected and time.time() - start_time > SILENCE_THRESHOLD:
                stop_recording = True

        try:
            with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, dtype='float32',
                                blocksize=FRAME_SIZE, callback=callback):
                while not stop_recording:
                    time.sleep(0.1)
        except sd.CallbackStop:
            pass

        if not buffer:
            return None

        return np.concatenate(buffer, axis=0)

    def is_speech(self, audio_bytes):
        return np.max(np.frombuffer(audio_bytes, dtype=np.int16)) > 500

    def publish_raw_voice(self, audio_np):
        self.get_logger().info("ì˜¤ë””ì˜¤ ë°ì´í„° WAV ì¸ì½”ë”© ì¤‘...")

        buf = io.BytesIO()
        with wave.open(buf, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16-bit PCM
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(audio_np.tobytes())

        wav_bytes = buf.getvalue()
        wav_uint8_array = np.frombuffer(wav_bytes, dtype=np.uint8)

        # âœ… RawVoice ë©”ì‹œì§€ ìƒì„± ë° í¼ë¸”ë¦¬ì‹œ
        msg = RawVoice()
        msg.robot_id = "pinky"
        msg.data = list(wav_uint8_array)

        self.get_logger().info(f"í¼ë¸”ë¦¬ì‹œ ì¤€ë¹„ ì™„ë£Œ - ê¸¸ì´: {len(msg.data)} bytes")
        self.raw_voice_pub_.publish(msg)
        self.get_logger().info("RawVoice ë©”ì‹œì§€ í¼ë¸”ë¦¬ì‹œ ì™„ë£Œ")

def main(args=None):
    rclpy.init(args=args)
    node = WakeWordListener()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
