import rclpy
from rclpy.node import Node
from std_msgs.msg import ByteMultiArray, String  # ë³€ê²½ëœ ë©”ì‹œì§€ íƒ€ì…
import whisper
import io
import wave
import numpy as np
import librosa
from tangerbot_msgs.msg import DecodedVoice
from tangerbot_msgs.srv import HandleRawVoice

# Whisper ëª¨ë¸ ë¡œë”© (ìµœì´ˆ 1íšŒ)
whisper_model = whisper.load_model("base")

class AudioToTextNode(Node):
    def __init__(self):
        super().__init__('audio_to_text_node')

        # ìŒì„± ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  í† í”½
        self.voice_srv = self.create_service(
            HandleRawVoice,
            'handle_raw_voice',
            self.audio_callback
        )
        
        # í…ìŠ¤íŠ¸ ì „ì†¡ í¼ë¸”ë¦¬ì…”
        self.text_publisher = self.create_publisher(DecodedVoice, '/decoded_voice', 10)

    def audio_callback(self, request, response):
        try:
            self.get_logger().info("ğŸ§ ì˜¤ë””ì˜¤ ìˆ˜ì‹ ")

            # UInt8MultiArray -> BytesIO
            audio_bytes = bytes(request.audio)
            wav_io = io.BytesIO(audio_bytes)

            # Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜
            recognized_text = self.transcribe_audio(wav_io)

            if recognized_text:
                self.get_logger().info(f"ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸: {recognized_text}")
                self.send_text_to_server(recognized_text)
                response.text = recognized_text
            else:
                self.get_logger().warn("âŒ í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤íŒ¨ ë˜ëŠ” ìŒì„± ì—†ìŒ")
                response.text = ""

        except Exception as e:
            self.get_logger().error(f"ğŸš¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            response.text = ""
        
        return response


    def transcribe_audio(self, wav_io):
        try:
            # WAV íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            with wave.open(wav_io, 'rb') as wf:
                sample_width = wf.getsampwidth()
                sample_rate = wf.getframerate()
                n_channels = wf.getnchannels()
                n_frames = wf.getnframes()
                audio_frames = wf.readframes(n_frames)

            # 16-bit PCM ê¸°ì¤€ numpy ë°°ì—´ ë³€í™˜
            audio_np = np.frombuffer(audio_frames, dtype=np.int16).astype(np.float32) / 32768.0  # Normalize to [-1.0, 1.0]

            # Whisperê°€ mono 16kHzë¥¼ ìš”êµ¬í•¨
            if n_channels > 1:
                audio_np = audio_np[::n_channels]  # ê°„ë‹¨í•œ ì±„ë„ ì••ì¶• (ì™¼ìª½ ì±„ë„ë§Œ ì‚¬ìš©)

            if sample_rate != 16000:
                self.get_logger().warn(f"âš ï¸ ìƒ˜í”Œë ˆì´íŠ¸ {sample_rate} -> 16000 ë³€í™˜ í•„ìš”")
                
                audio_np = librosa.resample(audio_np, orig_sr=sample_rate, target_sr=16000)

            # Whisper ì…ë ¥ ì¤€ë¹„
            audio_padded = whisper.pad_or_trim(audio_np)
            mel = whisper.log_mel_spectrogram(audio_padded).to(whisper_model.device)

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            result = whisper_model.decode(mel)
            return result.text

        except Exception as e:
            self.get_logger().error(f"âŒ Whisper ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None

    def send_text_to_server(self, text):
        msg = DecodedVoice()
        msg.text = text
        self.text_publisher.publish(msg)
        self.get_logger().info(f"ğŸ“¤ í…ìŠ¤íŠ¸ ì „ì†¡ ì™„ë£Œ: {text}")


def main(args=None):
    rclpy.init(args=args)
    node = AudioToTextNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
